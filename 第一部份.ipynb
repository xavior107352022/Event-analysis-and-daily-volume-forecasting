{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib as mpl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statsmodels.formula.api as smf\n",
    "#import statsmodels.tsa.api as smt\n",
    "#import statsmodels.api as sm\n",
    "import scipy.stats as scs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_event = pd.read_excel('MS_event17.xlsx')\n",
    "df_event['M_group'] = [ str(x)[4:6] for x in df_event.Date ]\n",
    "df_event['M_group_desc'] = [ str(x)[4:6] for x in df_event.Date_desclosure ]\n",
    "Event_list = df_event['Event.1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#讀取股價資料夾中 個別股價資料csv檔案\n",
    "import os\n",
    "Stocklist_infile =  os.listdir('C:\\\\Users\\\\user\\\\Desktop\\\\Untitled Folder\\\\MS\\\\MS_stock')\n",
    "from progressbar import ProgressBar\n",
    "total = len(Stocklist_infile)\n",
    "pbar = ProgressBar().start()\n",
    "timelist = []\n",
    "codelist = []\n",
    "\n",
    "openlist = []\n",
    "highlist =[]\n",
    "lowlist = []\n",
    "closelist =[]\n",
    "volumelist = []\n",
    "amountlist = []\n",
    "\n",
    "for i in range(0,len(Stocklist_infile)):\n",
    "    temp = pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Untitled Folder\\\\MS\\\\MS_stock\\\\'+Stocklist_infile[i],engine='python')\n",
    "    temp.columns = ['data']\n",
    "    \n",
    "    timelist.append(temp.data.str.split('\\t').str.get(0)[1:(len(temp.data.str.split('\\t').str.get(0)))-1])\n",
    "    codelist.append(np.repeat(Stocklist_infile[i][0:7]+'SZ',len(temp.data.str.split('\\t').str.get(0)[1:(len(temp.data.str.split('\\t').str.get(0)))-1])))\n",
    "    openlist.append(temp.data.str.split('\\t').str.get(1)[1:(len(temp.data.str.split('\\t').str.get(1)))-1])\n",
    "    highlist.append(temp.data.str.split('\\t').str.get(2)[1:(len(temp.data.str.split('\\t').str.get(2)))-1])\n",
    "    lowlist.append(temp.data.str.split('\\t').str.get(3)[1:(len(temp.data.str.split('\\t').str.get(3)))-1])\n",
    "    closelist.append(temp.data.str.split('\\t').str.get(4)[1:(len(temp.data.str.split('\\t').str.get(4)))-1])\n",
    "    volumelist.append(temp.data.str.split('\\t').str.get(5)[1:(len(temp.data.str.split('\\t').str.get(5)))-1])\n",
    "    amountlist.append(temp.data.str.split('\\t').str.get(6)[1:(len(temp.data.str.split('\\t').str.get(6)))-1])\n",
    "    \n",
    "    pbar.update(int((i/(total-1))*100))\n",
    "pbar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MS_PandQ = pd.DataFrame()\n",
    "df_MS_PandQ['Date'] =[ y for x in timelist for y in x ]\n",
    "df_MS_PandQ['Code'] =[ y for x in codelist for y in x ]\n",
    "df_MS_PandQ['Open'] =[ y for x in  openlist for y in x ]\n",
    "df_MS_PandQ['High'] =[ y for x in  highlist for y in x ]\n",
    "df_MS_PandQ['Low'] = [ y for x in lowlist for y in x ]\n",
    "df_MS_PandQ['Close'] = [ y for x in closelist for y in x ]\n",
    "df_MS_PandQ['Volume'] = [ y for x in volumelist for y in x ]\n",
    "df_MS_PandQ['Amount'] =[ y for x in  amountlist for y in x ]\n",
    "\n",
    "df_MS_PandQ['Open'] = df_MS_PandQ['Open'].astype('float')\n",
    "df_MS_PandQ['High'] = df_MS_PandQ['High'].astype('float')\n",
    "df_MS_PandQ['Low'] = df_MS_PandQ['Low'].astype('float')\n",
    "df_MS_PandQ['Close'] = df_MS_PandQ['Close'].astype('float')\n",
    "df_MS_PandQ['Volume'] = df_MS_PandQ['Volume'].astype('float')\n",
    "df_MS_PandQ['Amount'] =df_MS_PandQ['Amount'].astype('float')\n",
    "\n",
    "df_MS_PandQ.to_csv('MS_PandQ.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MS_PandQ=pd.read_csv('MS_PandQ.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#匯入產業類別資料\n",
    "df_IND = pd.read_excel('MS_IND.xlsx')\n",
    "df_IND.columns = ['Code','Name','CSRC_IND_Code','Wind_IND_Code']\n",
    "len(df_IND['Wind_IND_Code'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IND_list = df_IND['Wind_IND_Code'].unique()\n",
    "#      ['Wind制药、生物科技与生命科学', 'Wind材料Ⅱ', 'Wind耐用消费品与服装', 'Wind半导体与半导体生产设备',\n",
    "#       'Wind资本货物', 'Wind技术硬件与设备', 'Wind房地产Ⅱ', 'Wind能源Ⅱ', 'Wind零售业',\n",
    "#       'Wind媒体Ⅱ', 'Wind消费者服务Ⅱ', 'Wind商业和专业服务', 'Wind公用事业Ⅱ', 'Wind运输',\n",
    "#       'Wind食品、饮料与烟草', 'Wind医疗保健设备与服务', 'Wind汽车与汽车零部件', 'Wind软件与服务',\n",
    "#       'Wind家庭与个人用品', 'Wind银行', 'Wind食品与主要用品零售Ⅱ', 'Wind多元金融', 'Wind电信服务Ⅱ']\n",
    "for i in range(0,len(IND_list)):\n",
    "    df_IND['IND_dummy_'+str(i)] = ( df_IND['Wind_IND_Code'] == IND_list[i])*1 #dummy 1 是制药、生物科技与生命科学"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IND_list[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MS_PQ_Ind = pd.merge(left=df_MS_PandQ,right=df_IND,on=['Code'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_MS_PQ_Ind) == len(df_MS_PandQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 創造市值dummy 共5類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#讀取股價資料夾中 個別股價資料csv檔案\n",
    "import os\n",
    "Stocklist_infile =  os.listdir('C:\\\\Users\\\\user\\\\Desktop\\\\Untitled Folder\\\\MS\\\\CAP')\n",
    "from progressbar import ProgressBar\n",
    "total = len(Stocklist_infile)\n",
    "pbar = ProgressBar().start()\n",
    "datelist = []\n",
    "codelist = []\n",
    "turnoverlist = []\n",
    "caplist = []\n",
    "\n",
    "for i in range(0,len(Stocklist_infile)):\n",
    "    temp = pd.read_csv('C:\\\\Users\\\\user\\\\Desktop\\\\Untitled Folder\\\\MS\\\\CAP\\\\'+Stocklist_infile[i],engine='python')\n",
    "    temp.columns = ['Code','Name','Date','Amount','Turnover','Cap','unkown']\n",
    "    \n",
    "    datelist.append(temp.Date.values)\n",
    "    codelist.append(temp.Code.values)\n",
    "    turnoverlist.append(temp.Turnover.values)\n",
    "    caplist.append(temp.Cap.values)\n",
    "\n",
    "    pbar.update(int((i/(total-1))*100))\n",
    "pbar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Cap = pd.DataFrame()\n",
    "df_Cap['Date'] = [ x for y in datelist for x in y]\n",
    "df_Cap['Code'] = [ x for y in codelist for x in y]\n",
    "df_Cap['Tournover'] = [ x for y in  turnoverlist for x in y]\n",
    "df_Cap['Cap'] = [ x for y in caplist for x in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_Cap.to_csv('Cap_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MS_PQ_Ind_Cap = pd.merge(left = df_MS_PQ_Ind,right=df_Cap,on=['Date','Code'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_MS_PQ_Ind) ==len(df_MS_PQ_Ind_Cap) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "first_Quintile = df_MS_PQ_Ind_Cap.groupby('Date')['Cap'].apply(lambda x : np.where(np.array(x) < np.percentile(x,20),1,0))\n",
    "second_Quintile = df_MS_PQ_Ind_Cap.groupby('Date')['Cap'].apply( lambda x :np.where((np.array(x) >= np.percentile(x,20))&\n",
    "                                                                               (np.array(x) <  np.percentile(x,40))\n",
    "                                                                              ,1,0) )\n",
    "third_Quintile = df_MS_PQ_Ind_Cap.groupby('Date')['Cap'].apply( lambda x :np.where((np.array(x) >= np.percentile(x,40))&\n",
    "                                                                              (np.array(x) <  np.percentile(x,60))\n",
    "                                                                              ,1,0) )\n",
    "fourth_Quintile = df_MS_PQ_Ind_Cap.groupby('Date')['Cap'].apply( lambda x :np.where((np.array(x) >= np.percentile(x,60))&\n",
    "                                                                               (np.array(x) <  np.percentile(x,80))\n",
    "                                                                              ,1,0) )\n",
    "fifth_Quintile = df_MS_PQ_Ind_Cap.groupby('Date')['Cap'].apply(lambda x : np.where(np.array(x) >= np.percentile(x,80),1,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#由於上方是GroupbyDate 產出結果依照時間順序往下牌\n",
    "df_sortdate = df_MS_PQ_Ind_Cap.sort_values(['Date','Code'],ascending=[1,1]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sortdate['First_Quintile'] = [ y for x in first_Quintile for y in x]\n",
    "df_sortdate['Second_Quintile'] = [ y for x in second_Quintile for y in x]\n",
    "df_sortdate['Third_Quintile'] = [ y for x in third_Quintile for y in x]\n",
    "df_sortdate['Fourth_Quintile'] = [ y for x in fourth_Quintile for y in x]\n",
    "df_sortdate['Fifth_Quintile'] = [ y for x in fifth_Quintile for y in x]\n",
    "df_sortdate['Quintile_Class'] = df_sortdate['First_Quintile'].values*1+df_sortdate['Second_Quintile'].values*2+df_sortdate['Third_Quintile'].values*3+df_sortdate['Fourth_Quintile'].values*4+df_sortdate['Fifth_Quintile'].values*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_sortdate.groupby('Date')['Code'].count())\n",
    "print(df_sortdate.groupby('Date')['First_Quintile'].sum())\n",
    "print(df_sortdate.groupby('Date')['Second_Quintile'].sum())\n",
    "print(df_sortdate.groupby('Date')['Third_Quintile'].sum())\n",
    "print(df_sortdate.groupby('Date')['Fourth_Quintile'].sum())\n",
    "print(df_sortdate.groupby('Date')['Fifth_Quintile'].sum())#確定沒算錯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_MS_PQ_Ind_Cap = df_sortdate.sort_values(['Code','Date'],ascending=[1,1]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#取前后五天分析\n",
    "for i in range(-5,6):\n",
    "    df_MS_PQ_Ind_Cap['Volume_t'+str(i)] = df_MS_PQ_Ind_Cap.groupby('Code')['Volume'].shift(-i)\n",
    "#取T+1开盘价分析\n",
    "df_MS_PQ_Ind_Cap['Low_t-1'] = df_MS_PQ_Ind_Cap.groupby('Code')['Low'].shift(1)\n",
    "df_MS_PQ_Ind_Cap['High_t-1'] = df_MS_PQ_Ind_Cap.groupby('Code')['High'].shift(1)\n",
    "df_MS_PQ_Ind_Cap['Open_t+1'] = df_MS_PQ_Ind_Cap.groupby('Code')['Open'].shift(-1)\n",
    "df_MS_PQ_Ind_Cap['Chg_t-1~t%'] =( df_MS_PQ_Ind_Cap['Volume'].values - df_MS_PQ_Ind_Cap['Volume_t-1'].values)/df_MS_PQ_Ind_Cap['Volume_t-1'].values\n",
    "df_MS_PQ_Ind_Cap['Chg_t~t+1%'] =( df_MS_PQ_Ind_Cap['Volume_t1'].values - df_MS_PQ_Ind_Cap['Volume'].values)/df_MS_PQ_Ind_Cap['Volume'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#筛除缺少资料其间 与对其事件与价格量资料 5日\n",
    "df_MS_PQ_Ind_Cap=df_MS_PQ_Ind_Cap[(df_MS_PQ_Ind_Cap.Date.astype('int') > 20140720)&(df_MS_PQ_Ind_Cap.Date.astype('int') < 20180717)].reset_index(drop=True)\n",
    "df_event=df_event[df_event.Date.astype('int')<20180710].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_MS_PQ_Ind_Cap))\n",
    "print(len(df_event))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 將事件資料併入股價量價資料 left 量價 right 事件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_event.drop_duplicates().reset_index(drop=True)))\n",
    "print(len(df_event))#這兩個數有差異 表示有重複的事件資料\n",
    "df_event_dropdu = df_event.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_event_dropdu.Date = df_event_dropdu.Date.astype('str')\n",
    "df_MS_PQ_Ind_Cap.Date = df_MS_PQ_Ind_Cap.Date.astype('str')\n",
    "df_event_dropdu.Code = df_event_dropdu.Code.astype('str')\n",
    "df_MS_PQ_Ind_Cap.Code = df_MS_PQ_Ind_Cap.Code.astype('str')\n",
    "\n",
    "df_PandQ_Event = pd.merge(left=df_MS_PQ_Ind_Cap,right=df_event_dropdu ,on=['Date','Code'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PandQ_Event[((df_PandQ_Event.Date == '20140729') & (df_PandQ_Event.Code == '002306.SZ') )] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试有无为0得序列\n",
    "df_testzero = df_PandQ_Event[['Volume_t-5', 'Volume_t-4', 'Volume_t-3', 'Volume_t-2',\n",
    "       'Volume_t-1', 'Volume_t0', 'Volume_t1', 'Volume_t2', 'Volume_t3',\n",
    "       'Volume_t4', 'Volume_t5', 'Open_t+1']]\n",
    "for i in range(0,len(df_testzero.columns)):\n",
    "    print(sum((df_testzero.iloc[:,i] == 0)*1)) #很好都没有0的 下面就不会有无限大的可能安心算變動率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PandQ_Event['E_dummy1'] = (df_PandQ_Event['Event.1'] == '大宗交易')*1\n",
    "df_PandQ_Event['E_dummy2'] = (df_PandQ_Event['Event.1'] == '股權質押公告')*1\n",
    "df_PandQ_Event['E_dummy3'] = (df_PandQ_Event['Event.1'] == '撤消ST')*1\n",
    "df_PandQ_Event['E_dummy4'] = (df_PandQ_Event['Event.1'] == '纳入重要指数')*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_MS_PQ_Ind_Cap))\n",
    "df_PandQ_Event_dropMultiEvent = df_PandQ_Event[['Code','Date', 'Close','Volume',\n",
    "                                                'Chg_t~t+1%','Open_t+1','High','Low','Wind_IND_Code','Volume_t-5', 'Volume_t-4', 'Volume_t-3', 'Volume_t-2',\n",
    "                                                'Volume_t-1', 'Volume_t0', 'Volume_t1', 'Volume_t2', 'Volume_t3','Volume_t4', 'Volume_t5',\n",
    "                                               'IND_dummy_0' ,'IND_dummy_1' , 'IND_dummy_2' , 'IND_dummy_3' ,'IND_dummy_4',\n",
    "                                               'IND_dummy_5' ,'IND_dummy_6' , 'IND_dummy_7' , 'IND_dummy_8' ,'IND_dummy_9', \n",
    "                                               'IND_dummy_10','IND_dummy_11', 'IND_dummy_12', 'IND_dummy_13','IND_dummy_14',\n",
    "                                               'IND_dummy_15', 'IND_dummy_16','IND_dummy_17', 'IND_dummy_18', 'IND_dummy_19', \n",
    "                                                'IND_dummy_20','IND_dummy_21', 'IND_dummy_22', \n",
    "                                                'Cap', 'First_Quintile','Second_Quintile', 'Third_Quintile', 'Fourth_Quintile','Fifth_Quintile','Quintile_Class',\n",
    "                                                'Tournover'\n",
    "                                               ]].drop_duplicates().reset_index(drop=True) \n",
    "#長度必須等於8705088\n",
    "len(df_PandQ_Event_dropMultiEvent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PandQ_Event_dropMultiEvent['E_dummy1'] = df_PandQ_Event.groupby(['Code','Date'])['E_dummy1'].sum().tolist()\n",
    "df_PandQ_Event_dropMultiEvent['E_dummy2'] = df_PandQ_Event.groupby(['Code','Date'])['E_dummy2'].sum().tolist()\n",
    "df_PandQ_Event_dropMultiEvent['E_dummy3'] = df_PandQ_Event.groupby(['Code','Date'])['E_dummy3'].sum().tolist()\n",
    "df_PandQ_Event_dropMultiEvent['E_dummy4'] = df_PandQ_Event.groupby(['Code','Date'])['E_dummy4'].sum().tolist()\n",
    "df_PandQ_Event_dropMultiEvent['JumpHigh'] = np.where((df_PandQ_Event_dropMultiEvent['Open_t+1'].values  - df_PandQ_Event_dropMultiEvent['High'].values)>0,1,0 )\n",
    "df_PandQ_Event_dropMultiEvent['JumpLow'] = np.where((df_PandQ_Event_dropMultiEvent['Open_t+1'].values  - df_PandQ_Event_dropMultiEvent['Low'].values)<0,1,0 )\n",
    "\n",
    "df_PandQ_Event_dropMultiEvent['E_dummy1xJumpHigh'] = df_PandQ_Event_dropMultiEvent['E_dummy1'].values*df_PandQ_Event_dropMultiEvent['JumpHigh'].values\n",
    "df_PandQ_Event_dropMultiEvent['E_dummy1xJumpLow']  = df_PandQ_Event_dropMultiEvent['E_dummy1'].values*df_PandQ_Event_dropMultiEvent['JumpLow'].values\n",
    "df_PandQ_Event_dropMultiEvent['E_dummy2xJumpHigh'] = df_PandQ_Event_dropMultiEvent['E_dummy2'].values*df_PandQ_Event_dropMultiEvent['JumpHigh'].values\n",
    "df_PandQ_Event_dropMultiEvent['E_dummy2xJumpLow']  = df_PandQ_Event_dropMultiEvent['E_dummy2'].values*df_PandQ_Event_dropMultiEvent['JumpLow'].values\n",
    "df_PandQ_Event_dropMultiEvent['E_dummy3xJumpHigh'] = df_PandQ_Event_dropMultiEvent['E_dummy3'].values*df_PandQ_Event_dropMultiEvent['JumpHigh'].values\n",
    "df_PandQ_Event_dropMultiEvent['E_dummy3xJumpLow']  = df_PandQ_Event_dropMultiEvent['E_dummy3'].values*df_PandQ_Event_dropMultiEvent['JumpLow'].values\n",
    "df_PandQ_Event_dropMultiEvent['E_dummy4xJumpHigh'] = df_PandQ_Event_dropMultiEvent['E_dummy4'].values*df_PandQ_Event_dropMultiEvent['JumpHigh'].values\n",
    "df_PandQ_Event_dropMultiEvent['E_dummy4xJumpLow']  = df_PandQ_Event_dropMultiEvent['E_dummy4'].values*df_PandQ_Event_dropMultiEvent['JumpLow'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PandQ_Event_dropMultiEvent['Mean_Vpast5'] = np.mean(df_PandQ_Event_dropMultiEvent[['Volume_t-5', 'Volume_t-4', 'Volume_t-3',\n",
    "       'Volume_t-2', 'Volume_t-1']],axis=1)\n",
    "df_PandQ_Event_dropMultiEvent['Mean_Vfutrue3'] = np.mean(df_PandQ_Event_dropMultiEvent[['Volume','Volume_t1', 'Volume_t2',\n",
    "       ]],axis=1)\n",
    "df_PandQ_Event_dropMultiEvent['MeanF3lessMeanP5%'] = df_PandQ_Event_dropMultiEvent['Mean_Vfutrue3'].values/df_PandQ_Event_dropMultiEvent['Mean_Vpast5'].values-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PandQ_Event_dropMultiEventNa =df_PandQ_Event_dropMultiEvent.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "codelist = df_PandQ_Event_dropMultiEventNa.Code.unique()\n",
    "from progressbar import ProgressBar\n",
    "\n",
    "pbar = ProgressBar().start()\n",
    "total = len(codelist)\n",
    "for z in range(0,len(codelist)):\n",
    "\n",
    "    df = df_PandQ_Event_dropMultiEventNa[df_PandQ_Event_dropMultiEventNa.Code == codelist[z] ]\n",
    "    data=df[['Chg_t~t+1%','E_dummy1','E_dummy2','JumpHigh']]\n",
    "    data=data[(data['Chg_t~t+1%']<np.percentile(data['Chg_t~t+1%'],95)) & (data['Chg_t~t+1%']>np.percentile(data['Chg_t~t+1%'],5))]\n",
    "\n",
    "    plt.figure(figsize=(10,5),dpi=200)\n",
    "    plt.title('Scatter of Chg_t~t+1% '+str(codelist[z]))\n",
    "    plt.subplot(3,1,1)\n",
    "    colorlist = np.where(np.array(data['E_dummy1'])==1,'y','b')\n",
    "    plt.scatter(y=data['Chg_t~t+1%'],x=data.index,c=colorlist)\n",
    "    datablock = np.where(np.array(data['E_dummy1'])==1,data['Chg_t~t+1%'],np.nan)\n",
    "    plt.scatter(y=datablock,x=data.index,c=colorlist)\n",
    "\n",
    "    plt.subplot(3,1,2)\n",
    "    colorlist = np.where(np.array(data['E_dummy2'])==1,'r','b')\n",
    "    plt.scatter(y=data['Chg_t~t+1%'],x=data.index,c=colorlist)\n",
    "    datamortgage = np.where(np.array(data['E_dummy2'])==1,data['Chg_t~t+1%'],np.nan)\n",
    "    plt.scatter(y=datamortgage,x=data.index,c=colorlist)\n",
    "\n",
    "    plt.subplot(3,1,3)\n",
    "    colorlist = np.where(np.array(data['JumpHigh'])==1,'g','b')\n",
    "    plt.scatter(y=data['Chg_t~t+1%'],x=data.index,c=colorlist)\n",
    "    dataJumpHigh = np.where(np.array(data['JumpHigh'])==1,data['Chg_t~t+1%'],np.nan)\n",
    "    plt.scatter(y=dataJumpHigh,x=data.index,c=colorlist)\n",
    "    plt.savefig('C:\\\\Users\\\\user\\\\Desktop\\\\Untitled Folder\\\\MS\\\\allstock scatter\\\\'+codelist[z]+'.png')\n",
    "    pbar.update(int((z/(total-1))*100))\n",
    "pbar.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_PandQ_Event_dropMultiEventNa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PandQ_Event_dropMultiEventNa.groupby('E_dummy4')['Volume'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PandQ_Event_dropMultiEventNa.groupby('Quintile_Class')['Chg_t~t+1%'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 一、分析个个事件 - 大宗交易"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blocktrade = df_PandQ_Event_dropMultiEventNa[df_PandQ_Event_dropMultiEventNa[\"E_dummy1\"]==1].reset_index(drop=True)\n",
    "df_blocktrade['Jump'] = df_blocktrade['JumpHigh'].values + df_blocktrade['JumpLow'].values*-1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、1、系统1 次数累积图即累积成交量图\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pair T test \n",
    "import scipy as sp\n",
    "df_blocktrade['Mean_Vpast5'] = np.mean(df_blocktrade[['Volume_t-5', 'Volume_t-4', 'Volume_t-3',\n",
    "       'Volume_t-2', 'Volume_t-1']],axis=1)\n",
    "df_blocktrade['Mean_Vfutrue3'] = np.mean(df_blocktrade[['Volume','Volume_t1', 'Volume_t2',\n",
    "       ]],axis=1)\n",
    "df_blocktrade['MeanF3lessMeanP5%'] = df_blocktrade['Mean_Vfutrue3'].values/df_blocktrade['Mean_Vpast5'].values-1\n",
    "\n",
    "df_blocktrade_sumV= df_blocktrade[['Volume_t-5', 'Volume_t-4', 'Volume_t-3', 'Volume_t-2',\n",
    "       'Volume_t-1', 'Volume_t0', 'Volume_t1', 'Volume_t2', 'Volume_t3',\n",
    "       'Volume_t4', 'Volume_t5']].sum()\n",
    "\n",
    "#os.makedirs('T1lesblocktrade-1_figure',exiblocktrade_ok=False)\n",
    "plt.close()\n",
    "cwd = os.getcwd()\n",
    "plt.figure(figsize=(10,5),dpi=200)\n",
    "ind = np.arange(len(df_blocktrade_sumV.index))    # the x locations for the groups\n",
    "width = 0.35 \n",
    "\n",
    "\n",
    "\n",
    "plt.bar(ind, df_blocktrade_sumV.values, width, color='#d62728')\n",
    "\n",
    "plt.ylabel('Sum')\n",
    "\n",
    "plt.title('Sum of Volume')\n",
    "plt.xticks(ind, df_blocktrade_sumV.index,rotation=-30)\n",
    "plt.yticks(np.arange(150000000000, 200000000000,10000000000))\n",
    "plt.ylim(ymin = 150000000000)\n",
    "\n",
    "#plt.legend(df_blocktrade_sumV.index)\n",
    "plt.text(0,185000000000,'T-statistic '+str(round(sp.stats.ttest_rel(df_blocktrade['Mean_Vfutrue3'],df_blocktrade['Mean_Vpast5'] )[0],3))\n",
    "        )\n",
    "plt.text(0,180000000000,'P-value '+str(round(sp.stats.ttest_rel(df_blocktrade['Mean_Vfutrue3'],df_blocktrade['Mean_Vpast5'] )[1],10))\n",
    "        )\n",
    "plt.savefig(cwd+'\\\\VolumeSum_blocktrade.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rank = df_blocktrade[['Volume_t-5', 'Volume_t-4', 'Volume_t-3', 'Volume_t-2',\n",
    "       'Volume_t-1', 'Volume_t0', 'Volume_t1', 'Volume_t2', 'Volume_t3',\n",
    "       'Volume_t4', 'Volume_t5']].rank(axis=1,ascending =False)\n",
    "df_rankTop3 = pd.DataFrame()\n",
    "df_rankTop3['Top1'] = df_rank[df_rank == 1].sum(axis=0)\n",
    "df_rankTop3['Top2'] = df_rank[df_rank == 2].sum(axis=0)\n",
    "df_rankTop3['Top3'] = df_rank[df_rank == 3].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.makedirs('T1lessT-1_figure',exist_ok=False)\n",
    "plt.close()\n",
    "cwd = os.getcwd()\n",
    "plt.figure(figsize=(10,5),dpi=200)\n",
    "ind = np.arange(len(df_rankTop3.index))    # the x locations for the groups\n",
    "width = 0.35 \n",
    "\n",
    "Top1 =  df_rankTop3['Top1']\n",
    "Top2 =  df_rankTop3['Top2']\n",
    "Top3 =  df_rankTop3['Top3']\n",
    "\n",
    "plt.bar(ind, Top1.values, width, color='#d62728')\n",
    "plt.bar(ind, Top2, width, bottom=Top1)\n",
    "plt.bar(ind, Top3, width, bottom=Top2)\n",
    "plt.ylabel('Sum')\n",
    "\n",
    "plt.title('Sum of Top3')\n",
    "plt.xticks(ind, df_rankTop3.index,rotation=-30)\n",
    "plt.yticks(np.arange(0, 10000,1000))\n",
    "plt.legend( df_rankTop3.columns)\n",
    "\n",
    "\n",
    "plt.savefig(cwd+'\\\\MeanF3lessMeanP5%'+'\\\\MeanF3lessMeanP5%_'+'All'+'_Sum_of_Top3.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、2、系统2 正负圆饼图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blocktrade['V_t+1~t-1%'] = df_blocktrade['Volume_t1'].values -  df_blocktrade['Volume_t-1'].values \n",
    "#os.makedirs('MeanF3lessMeanP5%',exist_ok=False)\n",
    "plt.close()\n",
    "cwd = os.getcwd()\n",
    "data = df_blocktrade['MeanF3lessMeanP5%'].values\n",
    "data_posi = len(data[data>=0])\n",
    "data_nega = len(data[data<0])\n",
    "data = data[(data<np.percentile(data,95)) & (data>np.percentile(data,5))]#去除極值\n",
    "    \n",
    "plt.figure(figsize=(5,5),dpi = 150)\n",
    "plt.pie([data_posi,data_nega],autopct= '%.0f%%')\n",
    "plt.savefig(cwd+'\\\\MeanF3lessMeanP5%'+'\\\\MeanF3lessMeanP5%'+'All'+'_Pie.jpeg')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.makedirs('T1lessT-1_figure',exist_ok=False)\n",
    "plt.close()\n",
    "cwd = os.getcwd()\n",
    "data = df_blocktrade[df_blocktrade.Jump == 1]['MeanF3lessMeanP5%'].values\n",
    "data_posi = len(data[data>=0])\n",
    "data_nega = len(data[data<0])\n",
    "#data = data[(data<np.percentile(data,95)) & (data>np.percentile(data,5))]#去除極值\n",
    "    \n",
    "plt.figure(figsize=(5,5),dpi = 150)\n",
    "plt.pie([data_posi,data_nega],autopct= '%.0f%%')\n",
    "plt.savefig(cwd+'\\\\MeanF3lessMeanP5%'+'\\\\MeanF3lessMeanP5%'+'_JumpHigh'+'_Pie.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.makedirs('T1lessT-1_figure',exist_ok=False)\n",
    "plt.close()\n",
    "cwd = os.getcwd()\n",
    "data = df_blocktrade[df_blocktrade.Jump == -1]['MeanF3lessMeanP5%'].values\n",
    "data_posi = len(data[data>=0])\n",
    "data_nega = len(data[data<0])\n",
    "#data = data[(data<np.percentile(data,95)) & (data>np.percentile(data,5))]#去除極值\n",
    "    \n",
    "plt.figure(figsize=(5,5),dpi = 150)\n",
    "plt.pie([data_posi,data_nega],autopct= '%.0f%%')\n",
    "plt.savefig(cwd+'\\\\MeanF3lessMeanP5%'+'\\\\MeanF3lessMeanP5%'+'_JumpLow'+'_Pie.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df_PandQ_Event_dropMultiEventNa.groupby('E_dummy1')['MeanF3lessMeanP5%'].apply(lambda x : list(x[(x<np.percentile(x,95)) & (x>np.percentile(x,5))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5),dpi=200)\n",
    "data=df_PandQ_Event_dropMultiEventNa.groupby('E_dummy1')['MeanF3lessMeanP5%'].apply(lambda x : list(x[(x<np.percentile(x,95)) & (x>np.percentile(x,5))]))\n",
    "data1=df_PandQ_Event_dropMultiEventNa.groupby('E_dummy1xJumpHigh')['MeanF3lessMeanP5%'].apply(lambda x : list(x[(x<np.percentile(x,95)) & (x>np.percentile(x,5))]))\n",
    "data2=df_PandQ_Event_dropMultiEventNa.groupby('E_dummy1xJumpLow')['MeanF3lessMeanP5%'].apply(lambda x : list(x[(x<np.percentile(x,95)) & (x>np.percentile(x,5))]))\n",
    "ind = np.arange(2)\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.boxplot(data)\n",
    "plt.ylim(ymax = 2.5)\n",
    "plt.ylim(ymin = -0.7)\n",
    "plt.xticks([1,2], ['Normal','BlockTrade'])\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.boxplot(data1)\n",
    "plt.ylim(ymax = 2.5)\n",
    "plt.ylim(ymin = -0.7)\n",
    "plt.xticks([1,2], ['Normal','BlockTradexJumpHigh'])\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.boxplot(data2)\n",
    "plt.ylim(ymax = 2.5)\n",
    "plt.ylim(ymin = -0.7)\n",
    "plt.xticks([1,2], ['Normal','BlockTradexJumpLow'])\n",
    "plt.savefig(cwd+'\\\\MeanF3lessMeanP5%'+'\\\\MeanF3lessMeanP5%'+'_block'+'_compare.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、3、單一維度統計圖表 \n",
    "# 1.針對產業繪製Box plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = plt.figure(1, figsize=(20, 10))\n",
    "data = df_blocktrade.groupby('Wind_IND_Code')['MeanF3lessMeanP5%'].apply(lambda x : list(x[(x<np.percentile(x,95)) & (x>np.percentile(x,5))]))\n",
    "plt.boxplot(data)\n",
    "#ind = np.arange(1,len(data.index)+1)\n",
    "#plt.xticks(ind, data.index,rotation=-90)\n",
    "cwd = os.getcwd()\n",
    "plt.savefig(cwd+'\\\\'+'MeanF3lessMeanP5%'+'\\\\Ind_blocktrade_box.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blocktrade.groupby('Wind_IND_Code')['MeanF3lessMeanP5%'].apply(lambda x : list(x[(x<np.percentile(x,95)) & (x>np.percentile(x,5))])).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 产业解释 IND_list[18,19,22,23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PandQ_Event_dropMultiEventNa.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IND_list[19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blocktrade[df_blocktrade['IND_dummy_22']==1][['Code','Date']].to_csv('BlockTrade_telecom.csv')\n",
    "df_blocktrade[df_blocktrade['IND_dummy_21']==1][['Code','Date']].to_csv('BlockTrade_multifin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blocktrade[df_blocktrade['IND_dummy_21']==1][['Code','Date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blocktrade.groupby('Wind_IND_Code')['Cap'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PandQ_Event_dropMultiEventNa.groupby('IND_dummy_22')['Cap'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PandQ_Event_dropMultiEventNa.groupby('IND_dummy_21')['Cap'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blocktrade[df_blocktrade['IND_dummy_18']==1].Code.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(df_PandQ_Event_dropMultiEventNa.groupby('IND_dummy_18')['Volume'].describe(),2) #用品"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(df_PandQ_Event_dropMultiEventNa.groupby('IND_dummy_19')['Volume'].describe(),2) #银行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(df_PandQ_Event_dropMultiEventNa.groupby('IND_dummy_21')['Volume'].describe(),2) #多元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(df_PandQ_Event_dropMultiEventNa.groupby('IND_dummy_22')['Volume'].describe(),2)#电信"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(df_PandQ_Event_dropMultiEventNa.groupby('IND_dummy_13')['Volume'].describe(),3)#公用事业"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PandQ_Event_dropMultiEventNa[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.makedirs('T1lessT-1_figure',exist_ok=False)\n",
    "plt.close()\n",
    "cwd = os.getcwd()\n",
    "plt.figure(figsize=(10,5),dpi=200)\n",
    "data = df_blocktrade.groupby('Wind_IND_Code')['Cap'].mean()\n",
    "ind = np.arange(len(data.index))    # the x locations for the groups\n",
    "width = 0.35 \n",
    "\n",
    "\n",
    "plt.bar(ind, data.values, width, color='#d62728')\n",
    "\n",
    "plt.title('Sum of Top3')\n",
    "plt.xticks(ind, data.index,rotation=-30)\n",
    "plt.yticks(np.arange(0, 1000000000,100000000))\n",
    "plt.legend( data.index )\n",
    "\n",
    "\n",
    "#plt.savefig(cwd+'\\\\T1lessT-1_figure'+'\\\\T1lessT-1_'+'All'+'_Sum_of_Top3.jpeg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PandQ_Event_dropMultiEventNa.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blocktrade('Wind_IND_Code')['Volume'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 針對時間繪製Box plot - 觀察時間趨勢及季節趨勢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blocktrade['M_Group'] = [x[4:6] for x in df_blocktrade['Date']]\n",
    "df_blocktrade['YM_Group'] = [x[0:6] for x in df_blocktrade['Date']]\n",
    "M_Group_list = df_blocktrade['M_Group'].sort_values().unique()\n",
    "YM_Group_list = df_blocktrade['YM_Group'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(20, 10))\n",
    "data = df_blocktrade.groupby('YM_Group')['MeanF3lessMeanP5%'].apply(lambda x : list(x[(x<np.percentile(x,95)) & (x>np.percentile(x,5))]))\n",
    "plt.boxplot(data)\n",
    "ind = np.arange(1,len(data.index)+1)\n",
    "xticks = [x[2:6] for x in data.index]\n",
    "plt.xticks(ind,xticks)\n",
    "\n",
    "cwd = os.getcwd()\n",
    "plt.savefig(cwd+'\\\\'+'MeanF3lessMeanP5%'+'\\\\YMonth_blocktrade_box.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(20, 10))\n",
    "data = df_blocktrade.groupby('M_Group')['MeanF3lessMeanP5%'].apply(lambda x : list(x[(x<np.percentile(x,95)) & (x>np.percentile(x,5))]))\n",
    "plt.boxplot(data)\n",
    "ind = np.arange(1,len(data.index)+1)\n",
    "xticks = [x for x in data.index]\n",
    "plt.xticks(ind,xticks)\n",
    "cwd = os.getcwd()\n",
    "plt.savefig(cwd+'\\\\'+'MeanF3lessMeanP5%'+'\\\\Month_blocktrade_box.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 針對市值繪製Box plot - 觀察成交量是否有市值群聚現象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(20, 10))\n",
    "data = df_blocktrade.groupby('Quintile_Class')['MeanF3lessMeanP5%'].apply(lambda x : list(x[(x<np.percentile(x,95)) & (x>np.percentile(x,5))]))\n",
    "plt.boxplot(data)\n",
    "ind = np.arange(1,len(data.index)+1)\n",
    "\n",
    "plt.xticks(ind,data.index)\n",
    "\n",
    "cwd = os.getcwd()\n",
    "plt.savefig(cwd+'\\\\'+'MeanF3lessMeanP5%'+'\\\\Cap_blocktrade_box.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一、4、多維度統計圖表 - 了解交乘作用\n",
    "# 1.加熱圖 顯示時間與產業的變化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap(data, row_labels, col_labels, ax=None,\n",
    "            cbar_kw={}, cbarlabel=\"\", **kwargs):\n",
    "    \"\"\"\n",
    "    Create a heatmap from a numpy array and two lists of labels.\n",
    "\n",
    "    Arguments:\n",
    "        data       : A 2D numpy array of shape (N,M)\n",
    "        row_labels : A list or array of length N with the labels\n",
    "                     for the rows\n",
    "        col_labels : A list or array of length M with the labels\n",
    "                     for the columns\n",
    "    Optional arguments:\n",
    "        ax         : A matplotlib.axes.Axes instance to which the heatmap\n",
    "                     is plotted. If not provided, use current axes or\n",
    "                     create a new one.\n",
    "        cbar_kw    : A dictionary with arguments to\n",
    "                     :meth:`matplotlib.Figure.colorbar`.\n",
    "        cbarlabel  : The label for the colorbar\n",
    "    All other arguments are directly passed on to the imshow call.\n",
    "    \"\"\"\n",
    "\n",
    "    if not ax:\n",
    "        ax = plt.gca()\n",
    "\n",
    "    # Plot the heatmap\n",
    "    im = ax.imshow(data, **kwargs)\n",
    "\n",
    "    # Create colorbar\n",
    "    cbar = ax.figure.colorbar(im, ax=ax, **cbar_kw)\n",
    "    cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n",
    "\n",
    "    # We want to show all ticks...\n",
    "    ax.set_xticks(np.arange(data.shape[1]))\n",
    "    ax.set_yticks(np.arange(data.shape[0]))\n",
    "    # ... and label them with the respective list entries.\n",
    "    ax.set_xticklabels(col_labels)\n",
    "    ax.set_yticklabels(row_labels)\n",
    "\n",
    "    # Let the horizontal axes labeling appear on top.\n",
    "    ax.tick_params(top=True, bottom=False,\n",
    "                   labeltop=True, labelbottom=False)\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=-30, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Turn spines off and create white grid.\n",
    "    for edge, spine in ax.spines.items():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    ax.set_xticks(np.arange(data.shape[1]+1)-.5, minor=True)\n",
    "    ax.set_yticks(np.arange(data.shape[0]+1)-.5, minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"w\", linestyle='-', linewidth=3)\n",
    "    ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "\n",
    "    return im, cbar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blocktrade['M_Group'] = [x[4:6] for x in df_blocktrade['Date']]\n",
    "df_blocktrade['YM_Group'] = [x[0:6] for x in df_blocktrade['Date']]\n",
    "M_Group_list = df_blocktrade['M_Group'].sort_values().unique()\n",
    "YM_Group_list = df_blocktrade['YM_Group'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ind_list = df_blocktrade['Wind_IND_Code'].unique()\n",
    "\n",
    "list1 = []\n",
    "list2 = []\n",
    "\n",
    "for i in range(0,len(Ind_list)):\n",
    "    temp = df_blocktrade[df_blocktrade['Wind_IND_Code']==Ind_list[i]]\n",
    "    list2 = []\n",
    "    for z in range(0,len(YM_Group_list)):\n",
    "        temp2 = temp[temp['YM_Group']==YM_Group_list[z]]\n",
    "        list2.append(np.mean(temp2['MeanF3lessMeanP5%'][temp2['MeanF3lessMeanP5%']<1]))\n",
    "    list1.append(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(20, 10))\n",
    "heatmap(pd.DataFrame(list1),row_labels=range(0,len(Ind_list)),col_labels=YM_Group_list)\n",
    "\n",
    "plt.savefig(cwd+'\\\\'+'MeanF3lessMeanP5%'+'\\\\YMonth_Ind_Heat_blocktrade.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ind_list = df_blocktrade['Wind_IND_Code'].unique()\n",
    "\n",
    "list1 = []\n",
    "list2 = []\n",
    "\n",
    "for i in range(0,len(Ind_list)):\n",
    "    temp = df_blocktrade[df_blocktrade['Wind_IND_Code']==Ind_list[i]]\n",
    "    list2 = []\n",
    "    for z in range(0,len(M_Group_list)):\n",
    "        temp2 = temp[temp['M_Group']==M_Group_list[z]]\n",
    "        list2.append(np.mean(temp2['MeanF3lessMeanP5%'][temp2['MeanF3lessMeanP5%']<1]))\n",
    "    list1.append(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(20, 10))\n",
    "heatmap(pd.DataFrame(list1),row_labels=range(0,len(Ind_list)),col_labels=M_Group_list)\n",
    "\n",
    "plt.savefig(cwd+'\\\\'+'MeanF3lessMeanP5%'+'\\\\Month_Cap_Heat_blocktrade.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.加熱圖 顯示市值與时间的變化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_blocktrade['M_Group'] = [x[4:6] for x in df_blocktrade['Date']]\n",
    "df_blocktrade['YM_Group'] = [x[0:6] for x in df_blocktrade['Date']]\n",
    "M_Group_list = df_blocktrade['M_Group'].sort_values().unique()\n",
    "YM_Group_list = df_blocktrade['YM_Group'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cap_list = df_blocktrade['Quintile_Class'].sort_values().unique()\n",
    "\n",
    "list1 = []\n",
    "list2 = []\n",
    "\n",
    "for i in range(0,len(Cap_list)):\n",
    "    temp = df_blocktrade[df_blocktrade['Quintile_Class']==Cap_list[i]]\n",
    "    list2 = []\n",
    "    for z in range(0,len(YM_Group_list)):\n",
    "        temp2 = temp[temp['YM_Group']==YM_Group_list[z]]\n",
    "        list2.append(np.mean(temp2['MeanF3lessMeanP5%'][temp2['MeanF3lessMeanP5%']<1]))\n",
    "    list1.append(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(20, 10))\n",
    "heatmap(pd.DataFrame(list1),row_labels=['Quintile1','Quintile2','Quintile3','Quintile4','Quintile5'],col_labels=YM_Group_list)\n",
    "\n",
    "plt.savefig(cwd+'\\\\'+'MeanF3lessMeanP5%'+'\\\\YMonth_Cap_Heat_blocktrade.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cap_list = df_blocktrade['Quintile_Class'].sort_values().unique()\n",
    "\n",
    "list1 = []\n",
    "list2 = []\n",
    "\n",
    "for i in range(0,len(Cap_list)):\n",
    "    temp = df_blocktrade[df_blocktrade['Quintile_Class']==Cap_list[i]]\n",
    "    list2 = []\n",
    "    for z in range(0,len(M_Group_list)):\n",
    "        temp2 = temp[temp['M_Group']==M_Group_list[z]]\n",
    "        list2.append(np.mean(temp2['MeanF3lessMeanP5%'][temp2['MeanF3lessMeanP5%']<1]))\n",
    "    list1.append(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(20, 10))\n",
    "heatmap(pd.DataFrame(list1),row_labels=['Quintile1','Quintile2','Quintile3','Quintile4','Quintile5']\n",
    "        ,col_labels=M_Group_list)\n",
    "\n",
    "plt.savefig(cwd+'\\\\'+'MeanF3lessMeanP5%'+'\\\\Month_Cap_Heat_blocktrade.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、分析个个事件 - 股权质押"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ST=df_PandQ_Event_dropMultiEventNa[df_PandQ_Event_dropMultiEventNa['E_dummy3']==1].reset_index(drop=True)\n",
    "df_ST['Jump'] = df_ST['JumpHigh'].values + df_ST['JumpLow'].values*-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ST_sumV= df_ST[['Volume_t-5', 'Volume_t-4', 'Volume_t-3', 'Volume_t-2',\n",
    "       'Volume_t-1', 'Volume_t0', 'Volume_t1', 'Volume_t2', 'Volume_t3',\n",
    "       'Volume_t4', 'Volume_t5']].sum()\n",
    "\n",
    "df_ST['Mean_Vpast5'] = np.mean(df_ST[['Volume_t-5', 'Volume_t-4', 'Volume_t-3',\n",
    "       'Volume_t-2', 'Volume_t-1']],axis=1)\n",
    "df_ST['Mean_Vfutrue3'] = np.mean(df_ST[['Volume','Volume_t1', 'Volume_t2',\n",
    "       ]],axis=1)\n",
    "df_ST['MeanF3lessMeanP5%'] = df_ST['Mean_Vfutrue3'].values/df_ST['Mean_Vpast5'].values-1\n",
    "\n",
    "\n",
    "#os.makedirs('T1lesST-1_figure',exiST_ok=False)\n",
    "plt.close()\n",
    "cwd = os.getcwd()\n",
    "plt.figure(figsize=(10,5),dpi=200)\n",
    "ind = np.arange(len(df_ST_sumV.index))    # the x locations for the groups\n",
    "width = 0.35 \n",
    "\n",
    "\n",
    "\n",
    "plt.bar(ind, df_ST_sumV.values, width, color='#d62728')\n",
    "\n",
    "plt.ylabel('Sum')\n",
    "\n",
    "plt.title('Sum of Volume')\n",
    "plt.xticks(ind, df_ST_sumV.index,rotation=-30)\n",
    "#plt.yticks(np.arange(700000000, 1200000000,100000000))\n",
    "#plt.ylim(ymin=700000000)\n",
    "#plt.legend(df_ST_sumV.index)\n",
    "plt.text(0,550000000,'T-statistic '+str(round(scs.ttest_rel(df_ST['Mean_Vfutrue3'],df_ST['Mean_Vpast5'] )[0],3))\n",
    "        )\n",
    "plt.text(0,500000000,'P-value '+str(round(scs.ttest_rel(df_ST['Mean_Vfutrue3'],df_ST['Mean_Vpast5'] )[1],3))\n",
    "        )\n",
    "plt.savefig(cwd+'\\\\VolumeSum_ST.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、分析个个事件 - 股权质押"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mortgage=df_PandQ_Event_dropMultiEventNa[df_PandQ_Event_dropMultiEventNa['E_dummy2']==1].reset_index(drop=True)\n",
    "df_mortgage['Jump'] = df_mortgage['JumpHigh'].values + df_mortgage['JumpLow'].values*-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、1、系统1 次数累积图即累积成交量图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mortgage_sumV= df_mortgage[['Volume_t-5', 'Volume_t-4', 'Volume_t-3', 'Volume_t-2',\n",
    "       'Volume_t-1', 'Volume_t0', 'Volume_t1', 'Volume_t2', 'Volume_t3',\n",
    "       'Volume_t4', 'Volume_t5']].sum()\n",
    "\n",
    "df_mortgage['Mean_Vpast5'] = np.mean(df_mortgage[['Volume_t-5', 'Volume_t-4', 'Volume_t-3',\n",
    "       'Volume_t-2', 'Volume_t-1']],axis=1)\n",
    "df_mortgage['Mean_Vfutrue3'] = np.mean(df_mortgage[['Volume','Volume_t1', 'Volume_t2',\n",
    "       ]],axis=1)\n",
    "df_mortgage['MeanF3lessMeanP5%'] = df_mortgage['Mean_Vfutrue3'].values/df_mortgage['Mean_Vpast5'].values-1\n",
    "\n",
    "\n",
    "#os.makedirs('T1lesmortgage-1_figure',eximortgage_ok=False)\n",
    "plt.close()\n",
    "cwd = os.getcwd()\n",
    "plt.figure(figsize=(10,5),dpi=200)\n",
    "ind = np.arange(len(df_mortgage_sumV.index))    # the x locations for the groups\n",
    "width = 0.35 \n",
    "\n",
    "\n",
    "\n",
    "plt.bar(ind, df_mortgage_sumV.values, width, color='#d62728')\n",
    "\n",
    "plt.ylabel('Sum')\n",
    "\n",
    "plt.title('Sum of Volume')\n",
    "plt.xticks(ind, df_mortgage_sumV.index,rotation=-30)\n",
    "plt.yticks(np.arange(70000000000, 120000000000,10000000000))\n",
    "plt.ylim(ymin=70000000000)\n",
    "#plt.legend(df_mortgage_sumV.index)\n",
    "plt.text(0,105000000000,'T-statistic '+str(round(sp.stats.ttest_rel(df_mortgage['Mean_Vfutrue3'],df_mortgage['Mean_Vpast5'] )[0],3))\n",
    "        )\n",
    "plt.text(0,100000000000,'P-value '+str(round(sp.stats.ttest_rel(df_mortgage['Mean_Vfutrue3'],df_mortgage['Mean_Vpast5'] )[1],3))\n",
    "        )\n",
    "plt.savefig(cwd+'\\\\VolumeSum_mortgage.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rank = df_mortgage[['Volume_t-5', 'Volume_t-4', 'Volume_t-3', 'Volume_t-2',\n",
    "       'Volume_t-1', 'Volume_t0', 'Volume_t1', 'Volume_t2', 'Volume_t3',\n",
    "       'Volume_t4', 'Volume_t5']].rank(axis=1,ascending =False)\n",
    "df_rankTop3 = pd.DataFrame()\n",
    "df_rankTop3['Top1'] = df_rank[df_rank == 1].sum(axis=0)\n",
    "df_rankTop3['Top2'] = df_rank[df_rank == 2].sum(axis=0)\n",
    "df_rankTop3['Top3'] = df_rank[df_rank == 3].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.makedirs('T1lessT-1_figure',exist_ok=False)\n",
    "plt.close()\n",
    "cwd = os.getcwd()\n",
    "plt.figure(figsize=(10,5),dpi=200)\n",
    "ind = np.arange(len(df_rankTop3.index))    # the x locations for the groups\n",
    "width = 0.35 \n",
    "\n",
    "Top1 =  df_rankTop3['Top1']\n",
    "Top2 =  df_rankTop3['Top2']\n",
    "Top3 =  df_rankTop3['Top3']\n",
    "\n",
    "plt.bar(ind, Top1.values, width, color='#d62728')\n",
    "plt.bar(ind, Top2, width, bottom=Top1)\n",
    "plt.bar(ind, Top3, width, bottom=Top2)\n",
    "plt.ylabel('Sum')\n",
    "\n",
    "plt.title('Sum of Top3')\n",
    "plt.xticks(ind, df_rankTop3.index)\n",
    "plt.yticks(np.arange(0, 10000,1000))\n",
    "plt.legend( df_rankTop3.columns)\n",
    "\n",
    "\n",
    "plt.savefig(cwd+'\\\\MeanF3lessMeanP5%'+'\\\\MeanF3lessMeanP5%_'+'All'+'_Sum_of_Top3_Mortgage.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、2、系统2 正负圆饼图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.makedirs('T1lessT-1_figure',exist_ok=False)\n",
    "#df_mortgage['V_t+1~t-1%'] = df_mortgage['Volume_t1'].values -  df_mortgage['Volume_t-1'].values \n",
    "plt.close()\n",
    "cwd = os.getcwd()\n",
    "data = df_mortgage['MeanF3lessMeanP5%'].values\n",
    "data_posi = len(data[data>=0])\n",
    "data_nega = len(data[data<0])\n",
    "data = data[(data<np.percentile(data,95)) & (data>np.percentile(data,5))]#去除極值\n",
    "    \n",
    "plt.figure(figsize=(5,5),dpi = 150)\n",
    "plt.pie([data_posi,data_nega],autopct= '%.0f%%')\n",
    "plt.savefig(cwd+'\\\\MeanF3lessMeanP5%'+'\\\\MeanF3lessMeanP5%'+'_All'+'_Pie_mortgage.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.makedirs('T1lessT-1_figure',exist_ok=False)\n",
    "plt.close()\n",
    "cwd = os.getcwd()\n",
    "data = df_mortgage[df_mortgage.Jump == 1]['MeanF3lessMeanP5%'].values\n",
    "data_posi = len(data[data>=0])\n",
    "data_nega = len(data[data<0])\n",
    "#data = data[(data<np.percentile(data,95)) & (data>np.percentile(data,5))]#去除極值\n",
    "    \n",
    "plt.figure(figsize=(5,5),dpi = 150)\n",
    "plt.pie([data_posi,data_nega],autopct= '%.0f%%')\n",
    "plt.savefig(cwd+'\\\\MeanF3lessMeanP5%'+'\\\\MeanF3lessMeanP5%'+'_JumpHigh'+'_Pie_mortgage.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.makedirs('T1lessT-1_figure',exist_ok=False)\n",
    "plt.close()\n",
    "cwd = os.getcwd()\n",
    "data = df_mortgage[df_mortgage.Jump == -1]['MeanF3lessMeanP5%'].values\n",
    "data_posi = len(data[data>=0])\n",
    "data_nega = len(data[data<0])\n",
    "#data = data[(data<np.percentile(data,95)) & (data>np.percentile(data,5))]#去除極值\n",
    "    \n",
    "plt.figure(figsize=(5,5),dpi = 150)\n",
    "plt.pie([data_posi,data_nega],autopct= '%.0f%%')\n",
    "plt.savefig(cwd+'\\\\MeanF3lessMeanP5%'+'\\\\MeanF3lessMeanP5%'+'_JumpLow'+'_Pie_mortgage.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5),dpi=200)\n",
    "data=df_PandQ_Event_dropMultiEventNa.groupby('E_dummy2')['MeanF3lessMeanP5%'].apply(lambda x : list(x[(x<np.percentile(x,95)) & (x>np.percentile(x,5))]))\n",
    "data1=df_PandQ_Event_dropMultiEventNa.groupby('E_dummy2xJumpHigh')['MeanF3lessMeanP5%'].apply(lambda x : list(x[(x<np.percentile(x,95)) & (x>np.percentile(x,5))]))\n",
    "data2=df_PandQ_Event_dropMultiEventNa.groupby('E_dummy2xJumpLow')['MeanF3lessMeanP5%'].apply(lambda x : list(x[(x<np.percentile(x,95)) & (x>np.percentile(x,5))]))\n",
    "ind = np.arange(2)\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.boxplot(data)\n",
    "plt.ylim(ymax = 2.5)\n",
    "plt.ylim(ymin = -0.7)\n",
    "plt.xticks([1,2], ['Normal','Mortgage'])\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.boxplot(data1)\n",
    "plt.ylim(ymax = 2.5)\n",
    "plt.ylim(ymin = -0.7)\n",
    "plt.xticks([1,2], ['Normal','MortgagexJumpHigh'])\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.boxplot(data2)\n",
    "plt.ylim(ymax = 2.5)\n",
    "plt.ylim(ymin = -0.7)\n",
    "plt.xticks([1,2], ['Normal','MortgagexJumpLow'])\n",
    "plt.savefig(cwd+'\\\\MeanF3lessMeanP5%'+'\\\\MeanF3lessMeanP5%'+'_Mortgage'+'_compare.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、3、單一維度統計圖表 \n",
    "# 1.針對產業繪製Box plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_mortgage['MeanF5lessP5'] = df_mortgage['Mean_Vfutrue5'].values - df_mortgage['Mean_Vpast5'].values \n",
    "#df_mortgage['MeanF5lessP5%'] =(df_mortgage['Mean_Vfutrue5'].values - df_mortgage['Mean_Vpast5'].values) / df_mortgage['Mean_Vpast5'].values\n",
    "fig = plt.figure(1, figsize=(20, 10))\n",
    "plt.boxplot(df_mortgage.groupby('Wind_IND_Code')['MeanF3lessMeanP5%'].apply(lambda x : list(x[(x<np.percentile(x,95)) & (x>np.percentile(x,5))])))\n",
    "cwd = os.getcwd()\n",
    "plt.savefig(cwd+'\\\\'+'MeanF3lessMeanP5%'+'\\\\Ind_mortgage_box.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 針對時間繪製Box plot - 觀察時間趨勢及季節趨勢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mortgage['M_Group'] = [x[4:6] for x in df_mortgage['Date']]\n",
    "df_mortgage['YM_Group'] = [x[0:6] for x in df_mortgage['Date']]\n",
    "M_Group_list = df_mortgage['M_Group'].sort_values().unique()\n",
    "YM_Group_list = df_mortgage['YM_Group'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(20, 10))\n",
    "data = df_mortgage.groupby('YM_Group')['MeanF3lessMeanP5%'].apply(lambda x : list(x[(x<np.percentile(x,95)) & (x>np.percentile(x,5))]))\n",
    "plt.boxplot(data)\n",
    "ind = np.arange(1,len(data.index)+1)\n",
    "xticks = [x[2:6] for x in data.index]\n",
    "plt.xticks(ind,xticks)\n",
    "cwd = os.getcwd()\n",
    "plt.savefig(cwd+'\\\\'+'MeanF3lessMeanP5%'+'\\\\YMonth_mortgage_box.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(20, 10))\n",
    "data = df_mortgage.groupby('M_Group')['MeanF3lessMeanP5%'].apply(lambda x : list(x[(x<np.percentile(x,95)) & (x>np.percentile(x,5))]))\n",
    "plt.boxplot(data)\n",
    "ind = np.arange(1,len(data.index)+1)\n",
    "xticks = [x for x in data.index]\n",
    "plt.xticks(ind,xticks)\n",
    "cwd = os.getcwd()\n",
    "plt.savefig(cwd+'\\\\'+'MeanF3lessMeanP5%'+'\\\\Month_mortgage_box.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 針對市值繪製Box plot - 觀察成交量是否有市值群聚現象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(20, 10))\n",
    "data = df_mortgage.groupby('Quintile_Class')['MeanF3lessMeanP5%'].apply(lambda x : list(x[(x<np.percentile(x,95)) & (x>np.percentile(x,5))]))\n",
    "plt.boxplot(data)\n",
    "ind = np.arange(1,len(data.index)+1)\n",
    "\n",
    "plt.xticks(ind,data.index)\n",
    "cwd = os.getcwd()\n",
    "plt.savefig(cwd+'\\\\'+'MeanF3lessMeanP5%'+'\\\\Cap_mortgage_box.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二、4、多維度統計圖表 - 了解交乘作用\n",
    "# 1.加熱圖 顯示時間與產業的變化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mortgage['M_Group'] = [x[4:6] for x in df_mortgage['Date']]\n",
    "df_mortgage['YM_Group'] = [x[0:6] for x in df_mortgage['Date']]\n",
    "M_Group_list = df_mortgage['M_Group'].sort_values().unique()\n",
    "YM_Group_list = df_mortgage['YM_Group'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ind_list = df_mortgage['Wind_IND_Code'].unique()\n",
    "\n",
    "list1 = []\n",
    "list2 = []\n",
    "\n",
    "for i in range(0,len(Ind_list)):\n",
    "    temp = df_mortgage[df_mortgage['Wind_IND_Code']==Ind_list[i]]\n",
    "    list2 = []\n",
    "    for z in range(0,len(YM_Group_list)):\n",
    "        temp2 = temp[temp['YM_Group']==YM_Group_list[z]]\n",
    "        list2.append(np.mean(temp2['MeanF3lessMeanP5%'][temp2['MeanF3lessMeanP5%']<1]))\n",
    "    list1.append(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(20, 10))\n",
    "heatmap(pd.DataFrame(list1),row_labels=range(0,len(Ind_list)),col_labels=YM_Group_list)\n",
    "plt.savefig(cwd+'\\\\'+'MeanF3lessMeanP5%'+'\\\\YMonth_Ind_Heat_mortgage.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ind_list = df_mortgage['Wind_IND_Code'].unique()\n",
    "\n",
    "list1 = []\n",
    "list2 = []\n",
    "\n",
    "for i in range(0,len(Ind_list)):\n",
    "    temp = df_mortgage[df_mortgage['Wind_IND_Code']==Ind_list[i]]\n",
    "    list2 = []\n",
    "    for z in range(0,len(M_Group_list)):\n",
    "        temp2 = temp[temp['M_Group']==M_Group_list[z]]\n",
    "        list2.append(np.mean(temp2['MeanF3lessMeanP5%'][temp2['MeanF3lessMeanP5%']<1]))\n",
    "    list1.append(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(20, 10))\n",
    "heatmap(pd.DataFrame(list1),row_labels=range(0,len(Ind_list)),col_labels=M_Group_list)\n",
    "\n",
    "plt.savefig(cwd+'\\\\'+'MeanF3lessMeanP5%'+'\\\\Month_Cap_Heat_mortgage.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.加熱圖 顯示市值與產業的變化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mortgage['M_Group'] = [x[4:6] for x in df_mortgage['Date']]\n",
    "df_mortgage['YM_Group'] = [x[0:6] for x in df_mortgage['Date']]\n",
    "M_Group_list = df_mortgage['M_Group'].sort_values().unique()\n",
    "YM_Group_list = df_mortgage['YM_Group'].sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cap_list = df_mortgage['Quintile_Class'].sort_values().unique()\n",
    "\n",
    "list1 = []\n",
    "list2 = []\n",
    "\n",
    "for i in range(0,len(Cap_list)):\n",
    "    temp = df_mortgage[df_mortgage['Quintile_Class']==Cap_list[i]]\n",
    "    list2 = []\n",
    "    for z in range(0,len(YM_Group_list)):\n",
    "        temp2 = temp[temp['YM_Group']==YM_Group_list[z]]\n",
    "        list2.append(np.mean(temp2['MeanF3lessMeanP5%'][(temp2['MeanF3lessMeanP5%']<1)]))\n",
    "    list1.append(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(20, 10))\n",
    "heatmap(pd.DataFrame(list1),row_labels=['Quintile1','Quintile2','Quintile3','Quintile4','Quintile5'],col_labels=YM_Group_list)\n",
    "\n",
    "plt.savefig(cwd+'\\\\'+'MeanF3lessMeanP5%'+'\\\\YMonth_Cap_Heat_blocktrade.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cap_list = df_mortgage['Quintile_Class'].sort_values().unique()\n",
    "\n",
    "list1 = []\n",
    "list2 = []\n",
    "\n",
    "for i in range(0,len(Cap_list)):\n",
    "    temp = df_mortgage[df_mortgage['Quintile_Class']==Cap_list[i]]\n",
    "    list2 = []\n",
    "    for z in range(0,len(M_Group_list)):\n",
    "        temp2 = temp[temp['M_Group']==M_Group_list[z]]\n",
    "        list2.append(np.mean(temp2['MeanF3lessMeanP5%'][temp2['MeanF3lessMeanP5%']<1]))\n",
    "    list1.append(list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1, figsize=(20, 10))\n",
    "heatmap(pd.DataFrame(list1),row_labels=['Quintile1','Quintile2','Quintile3','Quintile4','Quintile5']\n",
    "        ,col_labels=M_Group_list)\n",
    "\n",
    "plt.savefig(cwd+'\\\\'+'MeanF3lessMeanP5%'+'\\\\Month_Cap_Heat_mortgage.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、分析个个事件 - 纳入重要指数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp=df_PandQ_Event_dropMultiEventNa[df_PandQ_Event_dropMultiEventNa['E_dummy4']==1].reset_index(drop=True)\n",
    "df_exp['Jump'] = df_exp['JumpHigh'].values + df_exp['JumpLow'].values*-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、1、系统1 次数累积图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp_sumV= df_exp[['Volume_t-5', 'Volume_t-4', 'Volume_t-3', 'Volume_t-2',\n",
    "       'Volume_t-1', 'Volume_t0', 'Volume_t1', 'Volume_t2', 'Volume_t3',\n",
    "       'Volume_t4', 'Volume_t5']].sum()\n",
    "df_exp['Mean_Vpast5'] = np.mean(df_exp[['Volume_t-5', 'Volume_t-4', 'Volume_t-3',\n",
    "       'Volume_t-2', 'Volume_t-1']],axis=1)\n",
    "df_exp['Mean_Vfutrue3'] = np.mean(df_exp[['Volume','Volume_t1', 'Volume_t2',\n",
    "       ]],axis=1)\n",
    "df_exp['MeanF3lessMeanP5%'] = df_exp['Mean_Vfutrue3'].values/df_exp['Mean_Vpast5'].values-1\n",
    "\n",
    "\n",
    "#os.makedirs('T1lesexp-1_figure',exiexp_ok=False)\n",
    "plt.close()\n",
    "cwd = os.getcwd()\n",
    "plt.figure(figsize=(10,5),dpi=200)\n",
    "ind = np.arange(len(df_exp_sumV.index))    # the x locations for the groups\n",
    "width = 0.35 \n",
    "\n",
    "\n",
    "\n",
    "plt.bar(ind, df_exp_sumV.values, width, color='#d62728')\n",
    "\n",
    "plt.ylabel('Sum')\n",
    "\n",
    "plt.title('Sum of Volume')\n",
    "plt.xticks(ind, df_exp_sumV.index,rotation=-30)\n",
    "plt.ylim(ymin=1000000000)\n",
    "#plt.yticks(np.arange(0, 100000000,10000000))\n",
    "#plt.legend(df_exp_sumV.index)\n",
    "plt.text(0,2200000000,'T-statistic '+str(round(sp.stats.ttest_rel(df_exp['Mean_Vfutrue3'],df_exp['Mean_Vpast5'] )[0],3))\n",
    "        )\n",
    "plt.text(0,2000000000,'P-value '+str(round(sp.stats.ttest_rel(df_exp['Mean_Vfutrue3'],df_exp['Mean_Vpast5'] )[1],3))\n",
    "        )\n",
    "plt.savefig(cwd+'\\\\VolumeSum_exp.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rank = df_exp[['Volume_t-5', 'Volume_t-4', 'Volume_t-3', 'Volume_t-2',\n",
    "       'Volume_t-1', 'Volume_t0', 'Volume_t1', 'Volume_t2', 'Volume_t3',\n",
    "       'Volume_t4', 'Volume_t5']].rank(axis=1,ascending =False)\n",
    "df_rankTop3 = pd.DataFrame()\n",
    "df_rankTop3['Top1'] = df_rank[df_rank == 1].sum(axis=0)\n",
    "df_rankTop3['Top2'] = df_rank[df_rank == 2].sum(axis=0)\n",
    "df_rankTop3['Top3'] = df_rank[df_rank == 3].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.makedirs('T1lessT-1_figure',exist_ok=False)\n",
    "plt.close()\n",
    "cwd = os.getcwd()\n",
    "plt.figure(figsize=(10,5),dpi=200)\n",
    "ind = np.arange(len(df_rankTop3.index))    # the x locations for the groups\n",
    "width = 0.35 \n",
    "\n",
    "Top1 =  df_rankTop3['Top1']\n",
    "Top2 =  df_rankTop3['Top2']\n",
    "Top3 =  df_rankTop3['Top3']\n",
    "\n",
    "plt.bar(ind, Top1.values, width, color='#d62728')\n",
    "plt.bar(ind, Top2, width, bottom=Top1)\n",
    "plt.bar(ind, Top3, width, bottom=Top2)\n",
    "plt.ylabel('Sum')\n",
    "\n",
    "plt.title('Sum of Top3')\n",
    "plt.xticks(ind, df_rankTop3.index)\n",
    "plt.yticks(np.arange(0, 10,50))\n",
    "plt.legend( df_rankTop3.columns)\n",
    "\n",
    "\n",
    "plt.savefig(cwd+'\\\\MeanF3lessMeanP5%'+'\\\\MeanF3lessMeanP5%_'+'All'+'_Sum_of_Top3_Exp.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三、2、系统2 正负圆饼图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.makedirs('T1lessT-1_figure',exist_ok=False)\n",
    "df_exp['V_t~t-1%'] = df_exp['Volume'].values - df_exp['Volume_t-1'].values \n",
    "plt.close()\n",
    "cwd = os.getcwd()\n",
    "data = df_exp['MeanF3lessMeanP5%'].values\n",
    "data_posi = len(data[data>=0])\n",
    "data_nega = len(data[data<0])\n",
    "data = data[(data<np.percentile(data,95)) & (data>np.percentile(data,5))]#去除極值\n",
    "    \n",
    "plt.figure(figsize=(5,5),dpi = 150)\n",
    "plt.pie([data_posi,data_nega],autopct= '%.0f%%')\n",
    "plt.savefig(cwd+'\\\\MeanF3lessMeanP5%'+'\\\\MeanF3lessMeanP5%'+'_All'+'_Pie_Exp.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.makedirs('T1lessT-1_figure',exist_ok=False)\n",
    "plt.close()\n",
    "cwd = os.getcwd()\n",
    "data = df_exp[df_exp.Jump == 1]['MeanF3lessMeanP5%'].values\n",
    "data_posi = len(data[data>=0])\n",
    "data_nega = len(data[data<0])\n",
    "#data = data[(data<np.percentile(data,95)) & (data>np.percentile(data,5))]#去除極值\n",
    "    \n",
    "plt.figure(figsize=(5,5),dpi = 150)\n",
    "plt.pie([data_posi,data_nega],autopct= '%.0f%%')\n",
    "plt.savefig(cwd+'\\\\MeanF3lessMeanP5%'+'\\\\MeanF3lessMeanP5%'+'_JumpHigh'+'_Pie_Exp.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.makedirs('T1lessT-1_figure',exist_ok=False)\n",
    "plt.close()\n",
    "cwd = os.getcwd()\n",
    "data = df_exp[df_exp.Jump == -1]['MeanF3lessMeanP5%'].values\n",
    "data_posi = len(data[data>=0])\n",
    "data_nega = len(data[data<0])\n",
    "#data = data[(data<np.percentile(data,95)) & (data>np.percentile(data,5))]#去除極值\n",
    "    \n",
    "plt.figure(figsize=(5,5),dpi = 150)\n",
    "plt.pie([data_posi,data_nega],autopct= '%.0f%%')\n",
    "plt.savefig(cwd+'\\\\MeanF3lessMeanP5%'+'\\\\MeanF3lessMeanP5%'+'_JumpLow'+'_Pie_Exp.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5),dpi=200)\n",
    "data=df_PandQ_Event_dropMultiEventNa.groupby('E_dummy3')['MeanF3lessMeanP5%'].apply(lambda x : x)\n",
    "data1=df_PandQ_Event_dropMultiEventNa.groupby('E_dummy3xJumpHigh')['MeanF3lessMeanP5%'].apply(lambda x : x)\n",
    "data2=df_PandQ_Event_dropMultiEventNa.groupby('E_dummy3xJumpLow')['MeanF3lessMeanP5%'].apply(lambda x : x)\n",
    "ind = np.arange(2)\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.boxplot(data)\n",
    "plt.ylim(ymax = 3)\n",
    "plt.ylim(ymin = -0.7)\n",
    "plt.xticks([1,2], ['Normal','ST'])\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.boxplot(data1)\n",
    "plt.ylim(ymax = 3)\n",
    "plt.ylim(ymin = -0.7)\n",
    "plt.xticks([1,2], ['Normal','STxJumpHigh'])\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.boxplot(data2)\n",
    "plt.ylim(ymax = 3)\n",
    "plt.ylim(ymin = -0.7)\n",
    "plt.xticks([1,2], ['Normal','STxJumpLow'])\n",
    "plt.savefig(cwd+'\\\\MeanF3lessMeanP5%'+'\\\\MeanF3lessMeanP5%'+'_ST'+'_compare.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
